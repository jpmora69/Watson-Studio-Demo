{"nbformat_minor": 1, "cells": [{"source": "Primero importamos las librer\u00edas necesarias", "cell_type": "markdown", "metadata": {}}, {"source": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cross_validation import train_test_split, cross_val_score\nfrom sklearn.metrics import accuracy_score,roc_auc_score, average_precision_score\nfrom sklearn.preprocessing import LabelEncoder\nimport seaborn as sns\nfrom sklearn.grid_search import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom scipy.stats import randint as sp_randint\n#from scikitplot.metrics import plot_lift_curve,plot_cumulative_gain #!pip install scikit-plot\nimport warnings\nwarnings.filterwarnings(\"ignore\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Ahora importe los datos para guardarlos como un \"Data frame\" y poder usarlos aqu\u00ed en el Notebook. Primero debe dar click a la celda de abajo que se encuentra vac\u00eda. Luego abra el panel derecho dando click en el siguiente \u00edcono que se encuentra arriba a la derecha:\n\n![2.PNG](attachment:2.PNG)\n\nDespu\u00e9s que cargue deber\u00e1 ver los archivos csv que previamente a cardagos. Busque \"Churn_Modeling.csv\", de click en \"Insert to code\" y luego \"Insert pandas DataFrame\"\n\n![1.png](attachment:1.png)\n\n\nCorra la celda.\n\n\n", "cell_type": "markdown", "attachments": {"2.PNG": {"image/png": "iVBORw0KGgoAAAANSUhEUgAAADoAAAA4CAYAAACsc+sjAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAADMSURBVGhD7ZNBCgIxEAT9mH/ybb4rVxG8RDxkKWEYNpsRobcL6jR9SMHupZ+E84U+ni85iUMVJA5VkDhUQeJQBYlDFSQOVZA4VEHiUAVJWej1dv9yz4ZG+1WJQ4+aPTy6ZftViUOPmj08umX7VcnP/tHhns1H7qokDlWQOHTW6HMcZjveqiUOnTV6eBaT3aokDp01engWk92qJH//R4fcVEkcqiBxqILEoQoShypIHKogcaiCxKEKEocqSByqINlCW2tyki1UHYdq0fsbRaXMkgP/FG0AAAAASUVORK5CYII="}, "1.png": {"image/png": "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"}}, "metadata": {"scrolled": true}}, {"source": "\n\n\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "El problema de taza de abandono de un banco tiene la particularidad de que del total de clientes solo un peque\u00f1o porcentaje es el que abandona el banco. En otras palabas, la variable \"Exited\" tiene muchos m\u00e1s \"0\" que \"1\". Para observar este comportamiento observemos la siguiente gr\u00e1fica.", "cell_type": "markdown", "metadata": {}}, {"source": "#Gr\u00e1fica de variable a predecir\nchurn_count=sns.countplot(df_data_1.Exited)\nchurn_count.set(xlabel=\"\u00bfEl cliente abandon\u00f3 el banco?\",ylabel=\"N\u00famero de clientes\",title=\"Distribuci\u00f3n del abandono\")\nplt.show()\n\nprint('Taza de abandono = ',str(100*sum(df_data_1.Exited==1)/len(df_data_1.Exited))+\"%\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Ahora se van a hacer los \u00faltimos paso de procesamiento de datos. Primero debemos separar los datos en las\nmatrices X,y. En \"X\" se guardan todas las variables que se van a usar para poder predecir y en \"y\"se guarda\nla variable \"Exited\" que es la que queremos predecir. \n\nLos aloritmos de machine learning no entienden bien cuando las variables son texto (Como es el caso de las variables \"Geography\" y \"Gender\". Para esto se usa una t\u00e9cnica llamada \"Label encoding\" que consiste en transformar cada palabra \u00fanica de las variables a un n\u00famero. Por ejemplo, en la variable \"Geography\" se podr\u00eda convertir France a 1 y Spain a 2. \n\nFinalmente, se separan los datos en dos conjuntos: uno de entrenamiento y otro de prueba.", "cell_type": "markdown", "metadata": {}}, {"source": "##Se crean las matrices X,y.\nX=df_data_1.drop('Exited',axis=1)#Eliminamos columnas\ny=df_data_1.Exited#Definimos variable a predecir\n\n\n##Se define funci\u00f3n que crea diccionarios para transformar los factores de las variables categ\u00f3ricas a n\u00fameros y viceversa.\ndef label_encoder(X,cols):\n    from collections import namedtuple\n    encode={}\n    decode={}\n    for i in cols:\n        le=LabelEncoder()\n        le.fit_transform(X[i])\n        encode[i]=dict(zip(le.classes_, le.transform(le.classes_)))\n        decode[i]=dict(zip(le.transform(le.classes_),le.classes_))\n    encoder_tuple = namedtuple('encoder_tuple', ['encode', 'decode'])\n    dictionaries=encoder_tuple(encode,decode)\n    return(dictionaries)\n\n\ncategoric=X.select_dtypes(include=['object']).columns#Guarda el nombre de las columnas categ\u00f3ricas.\n\ndictionaries=label_encoder(X,categoric)#Label encoder dictionaries\nX.replace(dictionaries.encode,inplace=True)#Codificamos las variables categ\u00f3ricas.\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=0)#Dividimos los datos en entrenamiento y prueba.\n\nm,n=X_train.shape#Extraemos las dimensiones de la matriz X de entrenamiento.\n\nX.head()#Observamos c\u00f3mo quedan las primeras 5 filas luego de la transformaci\u00f3n.", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "En esta secci\u00f3n se corre el algoritmo que determinar\u00e1 el modelo.\n\nLos modelos de machine learning requieren de ciertos par\u00e1metros que el usuario debe ingresar. Sin embargo, hacer esto a mano no es nada pr\u00e1ctico por lo que existen diferentes m\u00e9todos para \"automatizar\" el proceso.\nEl m\u00e9todo usado a continuaci\u00f3n se llama \"b\u00fasqueda aleatoria\". Para esto simplemente se seleccionan los par\u00e1metros que se quieren sintonizar y se establecen rangos de valores en los que se quieren que est\u00e9n los par\u00e1metros. El valor que toma cada variable es tomado aleatoriamente de este este rango en cada iteraci\u00f3n.\n\nFinalmente, se calcula la exactitud de los diferentes modelos y se escogen los par\u00e1metros del modelo con mejor exactitud.", "cell_type": "markdown", "metadata": {}}, {"source": "param_dist = {\"max_features\": sp_randint(int(np.sqrt(n)), int(3*n/4)),\n              \"min_samples_leaf\": sp_randint(1, 20)}#Se definen los hiperpar\u00e1metros para sintonizar el modelo\n\nclf= RandomForestClassifier(n_jobs=-1,n_estimators=#COLOCAR AQU\u00cd N\u00daMERO DE \u00c1RBOLES) #Se inicializa la instancia de Random Forest.\n\n#Corre b\u00fasqueda aleatorio por X iteraciones.\nn_iter_search = #COLOQUE AQU\u00cd EL N\u00daMERO DE ITERACIONES\nrandom_search_clf= RandomizedSearchCV(clf, param_distributions=param_dist,\n                                   n_iter=n_iter_search,cv=5,scoring=\"accuracy\",random_state=10)\n\nrandom_search_clf.fit(X_train, y_train)#Se entrena el modelo con los mejores par\u00e1metros encontrados.\n\nbest_estimator=random_search_clf.best_estimator_#Guarda el modelo.\nbest_score=random_search_clf.best_score_#Guarda el puntaje del mejor modelo\n\nprint(' Best params:',best_estimator,'\\n','Best score:',best_score)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Ya que el modelo est\u00e1 entrenado, procedemos a probarlo en el conjunto de prueba.\nPara esto realizamos las predicciones de estos datos y luego comparamos con los resultados reales.\nEsta comparaci\u00f3n se hace de acuerdo a varias m\u00e9tricas.", "cell_type": "markdown", "metadata": {}}, {"source": "y_pred=best_estimator.predict(X_test)#Predicciones binarias en el conjunto de prueba\ny_pred_proba=best_estimator.predict_proba(X_test)#Predicciones de probabilidad en el conjunto de prueba\n\naccuracy=accuracy_score(y_pred=y_pred,y_true=y_test)#Exactitud\nAUC=roc_auc_score(y_score=y_pred_proba[:,1],y_true=y_test)#AUC\naverage_precision_score=  average_precision_score(y_true=y_test,y_score=y_pred_proba[:,1])\n\nprint('Accuracy:'+str(np.round(accuracy*100,4))+\"%\",\"\\t\",'AUC:'+str(np.round(AUC*100,4))+\"%\",\"\\t\"\n     ,'average_precision_score:'+str(np.round(average_precision_score*100,4))+\"%\",\"\\t\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "------------------------------------------------------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------------------------------------------------------", "cell_type": "markdown", "metadata": {}}, {"source": "# Crear un API del modelo", "cell_type": "markdown", "metadata": {}}, {"source": "Se importan los respositorios de machine learning.", "cell_type": "markdown", "metadata": {}}, {"source": "from repository.mlrepositoryclient import MLRepositoryClient\nfrom repository.mlrepositoryartifact import MLRepositoryArtifact\nfrom repository.mlrepository import MetaProps, MetaNames", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Se guardan las credenciales del servicio de machine learning en un JSON para luego usar esta informaci\u00f3n.", "cell_type": "markdown", "metadata": {}}, {"source": "wml_credentials=", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Se autentica el servicio con las credenciales.", "cell_type": "markdown", "metadata": {}}, {"source": "ml_repository_client = MLRepositoryClient(wml_credentials['url'])\nml_repository_client.authorize(wml_credentials['username'], wml_credentials['password'])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Creamos un artefacto de modelo en la instancia del servicio de machine learning", "cell_type": "markdown", "metadata": {}}, {"source": "# Check if props is mandatory\nprops = MetaProps({MetaNames.AUTHOR_NAME:\"XXXXXXX\", MetaNames.AUTHOR_EMAIL:\"XXXXXXX\"})\nmodel_artifact = MLRepositoryArtifact(best_estimator, name=\"XXXXXXX\", meta_props=props)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "saved_model = ml_repository_client.models.save(model_artifact)\nsaved_model.meta.available_props()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Importar librer\u00edas y guardar credenciales\n\nPara poder acceder al REST API de Watson Machine Learning requerimos\nun token de acceso", "cell_type": "markdown", "metadata": {}}, {"source": "import urllib3, requests, json\n\nheaders = urllib3.util.make_headers(basic_auth='{}:{}'.format(wml_credentials['username'], wml_credentials['password']))\nurl = '{}/v3/identity/token'.format(wml_credentials['url'])\nresponse = requests.get(url, headers=headers)\nmltoken = json.loads(response.text).get('token')\nheader = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Creaci\u00f3n y obtenci\u00f3n del scoring url", "cell_type": "markdown", "metadata": {}}, {"source": "endpoint_instance = wml_credentials['url'] + \"/v3/wml_instances/\" + wml_credentials['instance_id']\nheader = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken} \n\nresponse_get_instance = requests.get(endpoint_instance, headers=header)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "endpoint_published_models = json.loads(response_get_instance.text).get('entity').get('published_models').get('url')\nprint(endpoint_published_models)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "header = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\n\nresponse_get = requests.get(endpoint_published_models, headers=header)", "cell_type": "code", "metadata": {"scrolled": false}, "outputs": [], "execution_count": null}, {"source": "[endpoint_deployments] = [x.get('entity').get('deployments').get('url') for x in json.loads(response_get.text).get('resources') if x.get('metadata').get('guid') == saved_model.uid]\n\nprint(endpoint_deployments)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Despliegue del modelo", "cell_type": "markdown", "metadata": {}}, {"source": "Ahora podemos realizar el despliegue online del modelo publicado", "cell_type": "markdown", "metadata": {}}, {"source": "payload_online = {\"name\": \"XXXXXXX\", \"description\": \"Churn predction using Random Forest\", \"type\": \"online\"}\nresponse_online = requests.post(endpoint_deployments, json=payload_online, headers=header)\nprint(response_online.text)\n", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "# Scoring del modelo", "cell_type": "markdown", "metadata": {}}, {"source": "URL del API del modelo", "cell_type": "markdown", "metadata": {}}, {"source": "scoring_url = json.loads(response_online.text).get('entity').get('scoring_url')\nprint(scoring_url)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Ahora vamos a probar el modelo con datos de prueba ingresados por ustedes. Corra la siguiente celda y llene las celdas que se le solicitan\nque son necesarias para realizar la predicci\u00f3n. Esta celda guarda estos valores y los pre-procesa para que pueda ser usado por el modelo. Se genera un JSON que ser\u00e1 la entrada al modelo.", "cell_type": "markdown", "metadata": {}}, {"source": "Credit_score=int(input(\"Credit score: \"))\nGeography=input(\"Geography: \")\nGender=input(\"Gender: \")\nAge=int(input(\"Age: \"))\nTenure=int(input(\"Tenure: \"))\nBalance=int(input(\"Balance: \"))\nNum_products=int(input(\"Number of products: \"))\nHasCrCard=input(\"Has credit card: \")\nIsActiveMember=input(\"Is active member: \")\nEstimadedSalary=int(input(\"Estimated salary\"))\n\n\n\nnew_observation=np.array([[Credit_score,Geography,Gender,Age,Tenure,Balance,Num_products,HasCrCard,IsActiveMember,EstimadedSalary]],dtype=object)\nnew_observation=pd.DataFrame(new_observation,columns=X.columns)\nnew_observation.replace(dictionaries.encode,inplace=True)\n\npayload_scoring={'values':[list(new_observation.values[0])]}\nprint(payload_scoring)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "Al correr la celda de abajo se est\u00e1 ingresando el JSON anteriormente generado y se est\u00e1 haciendo el request a la API.", "cell_type": "markdown", "metadata": {}}, {"source": "response_scoring=requests.post(scoring_url,json=payload_scoring,headers=header)\nresponse=json.loads(response_scoring.text)\nprobabilidad_abandono=response['values'][0][1][1]\nprint(\"Este cliente tiene una probabilidad de\",np.round(probabilidad_abandono,2),\"de abandonar el banco\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "------------------------------------------------------------------------------------------------------------------------------------------\n------------------------------------------------------------------------------------------------------------------------------------------\n\nSecci\u00f3n adicional si queda tiempo", "cell_type": "markdown", "metadata": {}}, {"source": "def uplift(y_true,y_pred,percentile,expected_response_rate):\n    \n    n=int(np.round(len(y_true)*percentile))\n    y_true=y_true.astype(int)\n    \n    temp=pd.DataFrame({'y_pred': y_pred[:,1], 'y_true': y_true})\n    temp=temp.sort_values(by='y_pred',ascending=False).iloc[0:n,:]\n    \n    response_rate=sum(temp.y_true)/len(temp.y_true)\n    lift=response_rate/expected_response_rate\n    \n    return(lift)\n\npercentile=0.1\nexpected_response_rate=0.2\n\nuplift_score=make_scorer(uplift,greater_is_better=True,needs_proba=True,percentile=percentile,expected_response_rate=expected_response_rate)\n\nuplift_cv=np.mean(cross_val_score(best_estimator,X_train,y_train.astype(int),cv=5,scoring=uplift_score))\n\nprint('Cross validation uplift:',uplift_cv)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": null}, {"source": "#Lift and gain cumulative gain charts\n\ny_pred=best_estimator.predict_proba(X_test)\nprint(uplift(y_pred=y_pred,y_true=y_test,percentile=percentile,expected_response_rate=expected_response_rate))\n\nplot_cumulative_gain(y_test, y_pred, title='Cumulative Gains Curve')\nplt.show()\n\nplot_lift_curve(y_test, y_pred, title='Lift curve')\nplt.show()\n", "cell_type": "code", "metadata": {"scrolled": true}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}